{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Schostic_Gradient_Descent():\n",
    "\n",
    "\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "        self.coef_ = np.random.randn(X_train.shape[1]) * 0.01\n",
    "        self.intercept_ = 0\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            for j in range(X_train.shape[0]):\n",
    "\n",
    "                idx = np.random.randint(X_train.shape[0])\n",
    "\n",
    "                y_hat = np.dot(X_train[idx], self.coef_) + self.intercept_\n",
    "\n",
    "                intercept_slope = y_train[idx] - y_hat\n",
    "                self.intercept_ = self.intercept_ + (self.lr * intercept_slope)\n",
    "\n",
    "                coef_slope = np.dot((y_train[idx] - y_hat), X_train[idx])\n",
    "                self.coef_ = self.coef_ + (self.lr * coef_slope)\n",
    "\n",
    "        print(f\"Intercept_: {self.intercept_}, Coef_: {self.coef_}\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "\n",
    "        X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "        y_pred = np.dot(X_test, self.coef_) + self.intercept_\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = Schostic_Gradient_Descent(learning_rate=0.01, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept_: 74.87618140763692, Coef_: [  74.88725463   54.83768117  -93.01661386  361.14868155  250.46518524\n",
      "   -4.47377699  -40.0164761  -186.16921575  150.55931268  283.4016494\n",
      "  152.86797325]\n"
     ]
    }
   ],
   "source": [
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4449446504137342"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
