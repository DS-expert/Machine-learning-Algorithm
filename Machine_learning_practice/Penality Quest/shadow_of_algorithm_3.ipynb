{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_sk = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4526027629719195"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch_Gradient_Descent():\n",
    "\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "\n",
    "        self.coef_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "        self.coef_ = np.random.randn(X_train.shape[1]) * 0.01\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            y_hat = np.dot(X_train, self.coef_)\n",
    "            \n",
    "            error = y_train - y_hat\n",
    "\n",
    "            coef_slope = -2 * np.mean(np.dot(error, X_train))\n",
    "            self.coef_ = self.coef_ + (self.lr * coef_slope)\n",
    "        \n",
    "        print(f\"Coef: {self.coef_}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        X_test = np.insert(X_test, 0,1, axis=1)\n",
    "        y_pred = np.dot(X_test, self.coef_)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgd = Batch_Gradient_Descent(learning_rate=0.000001, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [-0.83836058 -0.85517677 -0.86030476 -0.83743134 -0.83786154 -0.83795499\n",
      " -0.83501017 -0.84213638 -0.83161761 -0.82800224 -0.82945847]\n"
     ]
    }
   ],
   "source": [
    "bgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.059092899613389"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Schostic_Gradient_Descent():\n",
    "\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "\n",
    "        self.coef_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "        self.coef_ = np.random.randn(X_train.shape[1]) * 0.01\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            for j in range(X_train.shape[0]):\n",
    "\n",
    "                idx = np.random.randint(X_train.shape[0])\n",
    "                \n",
    "                y_hat = np.dot(X_train[idx], self.coef_)\n",
    "\n",
    "                error = y_train[idx] - y_hat\n",
    "\n",
    "                coef_slope = np.dot(error, X_train[idx])\n",
    "                self.coef_ = self.coef_ + (self.lr * coef_slope)\n",
    "\n",
    "        print(f\"Coef: {self.coef_}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "        y_pred = np.dot(X_test, self.coef_)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = Schostic_Gradient_Descent(learning_rate=0.0000001, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [ 1.06438703 -0.00883661  0.00462916  0.01700334 -0.00531265  0.0189108\n",
      " -0.00726084 -0.010801    0.01604381  0.01220176  0.02604871]\n"
     ]
    }
   ],
   "source": [
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.952527041857258"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatch_Gradient_Descent():\n",
    "\n",
    "    def __init__(self,batch_size, learning_rate, epochs):\n",
    "\n",
    "        self.coef_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "        self.coef_ = np.random.randn(X_train.shape[1]) * 0.01\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            for j in range(int(X_train.shape[0] / self.batch_size)):\n",
    "\n",
    "                idx = np.random.choice(X_train.shape[0], self.batch_size, replace=False)\n",
    "\n",
    "                y_hat = np.dot(X_train[idx], self.coef_)\n",
    "\n",
    "                error = y_train[idx] - y_hat\n",
    "\n",
    "                coef_slope = -2 * np.dot(error, X_train[idx]) / self.batch_size\n",
    "                self.coef_ = self.coef_ + (self.lr * coef_slope)\n",
    "\n",
    "        print(f\"Coef: {self.coef_}\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_test = np.insert(X_test, 0,1, axis=1)\n",
    "        y_pred = np.dot(X_test, self.coef_)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgd = MiniBatch_Gradient_Descent(batch_size=32, learning_rate=0.000001, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [-0.3481779   0.01324484 -0.00818749 -0.02243279 -0.01724929 -0.00206502\n",
      " -0.02435881  0.00036989 -0.00632423  0.00296994  0.00183325]\n"
     ]
    }
   ],
   "source": [
    "mgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3 = mgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.030126377342215"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
