{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5daefd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6fb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343440fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d0963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree_():\n",
    "\n",
    "    def __init__(self, max_depth=None):\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "    \n",
    "    def gini(self, y):\n",
    "\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        p = counts / counts.sum()\n",
    "\n",
    "        return 1 - np.sum(p ** 2)\n",
    "\n",
    "    def best_split(self, X_train, y_train):\n",
    "\n",
    "        best_gini = float(\"inf\")\n",
    "        best_features = None\n",
    "        best_value = None\n",
    "\n",
    "        n_samples, n_features = X_train.shape\n",
    "\n",
    "        for feature in range(n_features):\n",
    "\n",
    "            values = np.unique(X_train[:, feature])\n",
    "\n",
    "            for value in values:\n",
    "\n",
    "                left_mask = X_train[:, feature] <= value\n",
    "                right_mask = X_train[:, feature] > value\n",
    "\n",
    "                y_left = y_train[left_mask]\n",
    "                y_right = y_train[right_mask]\n",
    "\n",
    "                gini_left = self.gini(y_left)\n",
    "                gini_right = self.gini(y_right)\n",
    "\n",
    "                weighted_gini = (len(y_left) * gini_left + len(y_right) * gini_right) / n_samples\n",
    "\n",
    "                if weighted_gini < best_gini:\n",
    "\n",
    "                    best_gini = weighted_gini\n",
    "                    best_features = feature\n",
    "                    best_value = value\n",
    "        \n",
    "        return best_features, best_value\n",
    "\n",
    "    def build_tree(self, X_train, y_train, depth=0):\n",
    "\n",
    "        count_classes = np.bincount(y_train)\n",
    "        majorities_class = np.argmax(count_classes)\n",
    "\n",
    "        if len(set(y_train)) == 1 or len(y_train) == 0 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "\n",
    "            return {\"leaf\": True, \"class\": majorities_class}\n",
    "        \n",
    "        best_features, best_values = self.best_split(X_train, y_train)\n",
    "\n",
    "        if best_features is None:\n",
    "\n",
    "            return {\"leaf\": True, \"class\": majorities_class}\n",
    "\n",
    "        left_mask = X_train[:, best_features] <= best_values\n",
    "        right_mask = X_train[:, best_features] > best_values\n",
    "\n",
    "        left_tree = self.build_tree(X_train[left_mask], y_train[left_mask], depth + 1)\n",
    "        right_tree = self.build_tree(X_train[right_mask], y_train[right_mask], depth + 1)\n",
    "\n",
    "        return {\n",
    "            \"leaf\": False,\n",
    "            \"feature\": best_features,\n",
    "            \"value\": best_values,\n",
    "            \"left\": left_tree,\n",
    "            \"right\": right_tree\n",
    "        }\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        self.tree = self.build_tree(X_train, y_train)\n",
    "    \n",
    "    def predict_one(self, X_test):\n",
    "\n",
    "        node = self.tree\n",
    "\n",
    "        while not node[\"leaf\"]:\n",
    "\n",
    "            if X_test[node[\"feature\"]] <= node[\"value\"]:\n",
    "                node = node[\"left\"]\n",
    "            else:\n",
    "                node = node[\"right\"]\n",
    "\n",
    "        return node[\"class\"]\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "\n",
    "        return np.array([self.predict_one(x) for x in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "667c5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "\n",
    "    def __init__(self, n_estimators, max_depth=None):\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = []\n",
    "    \n",
    "    def bootsrap(self, X_train, y_train):\n",
    "\n",
    "        n_samples = X_train.shape[0]\n",
    "\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "\n",
    "        return X_train[indices], y_train[indices]\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "\n",
    "            X_sample, y_sample = self.bootsrap(X_train, y_train)\n",
    "\n",
    "            tree = DecisionTree_(max_depth=self.max_depth)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "\n",
    "            self.tree.append(tree)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "\n",
    "        tree_pred = np.array([tree.predict(X_test) for tree in self.tree])\n",
    "\n",
    "        tree_preds = tree_pred.T\n",
    "\n",
    "        final_pred = np.array([Counter(row).most_common(1)[0][0] for row in tree_preds])\n",
    "\n",
    "        return final_pred\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2503833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_ = RandomForest(n_estimators=10, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f87162",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee552ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd4875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0ebfe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6689a211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
